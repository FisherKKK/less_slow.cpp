// ----------------------------------------------------------------------------
// less_slow_ptx.ptx
// Micro-kernels for building a performance-first mindset for CUDA-capable
// GPUs using Parallel Thread eXecution (PTX) Intermediate Representation (IR) 
// for different generations of Streaming Multiprocessors (SMs) and Tensor
// Cores (TCs).
//
// ? You should start at `less_slow.cu` before reading this file.
// ? Also read intro to PTX: https://docs.nvidia.com/cuda/parallel-thread-execution/
// ? Check the PTX ISA: https://docs.nvidia.com/cuda/pdf/ptx_isa_8.5.pdf
// 
// ! PTX is higher-level than SASS, but still very similar to typical CPU 
// ! assembly languages. It has slightly different syntax and semantics for
// ! predicates and memory access, but still don't have `for` loops :(
// ! As for emojis, we can only use ASCII... CUDA can't JIT-compile UTF-8.
//
// You can validate this file by asking the Nvidia PTX Assembler to compile it
// to `.cubin` for some target architecture:
//
// $ ptxas -o less_slow_from_ptx.cubin -arch=sm_70 less_slow.ptx
// $ cuobjdump -sass less_slow_from_ptx.cubin | grep -i mma
//
// ## Register File
//
// GPU code manages registers differently. Hopper tuning guide suggests that
// the register file size is 64K 32-bit registers per Streaming Multiprocessor.
// The maximum number of registers per thread is 255.
//
// PTX provides read-only variables visible a special registers like `%tid` for
// thread ID, `%ctaid` for block ID, and `%aggr_smem_size` for shared memory,
// or `%current_graph_exec` to access the ID of the current graph execution.
// To read from them, simple use the `mov` instruction.
// ----------------------------------------------------------------------------

.version 6.5                          // PTX version 6.5 is enough for Volta GPUs
.target sm_70                         // Target architecture (SM 7.0 - Volta GPUs)
.address_size 64                      // 64-bit addressing

.visible .entry tops_f16f32_sm70tc_16x16x16_1024loop_ptx_kernel()
{
    // Register declarations
    .reg .f32  %f<9>;                 // Floating-point registers for accumulators
    .reg .b32  %r<3>;                 // General-purpose registers for loop counter and packed inputs
    .reg .pred %p;                    // Predicate register for conditional branching

    // Initialize the loop counter; but keep in mind, that an algorithm with a
    // loop will be a lot slower than PTX kernels generated by the CUDA compiler.
    // Those end up unrolling thousands of iterations into a single kernel!
    mov.u32    %r0, 0;                // %r0 = loop counter, start at 0
    mov.u32    %r1, 1024;             // %r1 = loop limit (1024 iterations)

    // Zero-initialize accumulators
    mov.f32    %f0, 0.0;              // Initialize %f0 to zero
    mov.f32    %f1, 0.0;              // Initialize %f1 to zero
    mov.f32    %f2, 0.0;              // Initialize %f2 to zero
    mov.f32    %f3, 0.0;              // Initialize %f3 to zero
    mov.f32    %f4, 0.0;              // Initialize %f4 to zero
    mov.f32    %f5, 0.0;              // Initialize %f5 to zero
    mov.f32    %f6, 0.0;              // Initialize %f6 to zero
    mov.f32    %f7, 0.0;              // Initialize %f7 to zero

    // Packed matrix inputs (example placeholders)
    mov.b32    %r2, 0x00010001;       // Packed 16-bit values (placeholder for matrix A and B)

    // Loop start
loop_start:
    setp.ge.u32 %p, %r0, %r1;         // Compare loop counter (%r0) with limit (%r1)
    @%p bra loop_exit;                // Exit loop if %r0 >= %r1

    // Tensor Core MMA operation
    wmma.mma.sync.aligned.row.col.m16n16k16.f32.f32 
        {%f0, %f1, %f2, %f3, %f4, %f5, %f6, %f7}, // Accumulators (output)
        {%r1, %r1, %r1, %r1, %r1, %r1, %r1, %r1}, // Matrix A (packed 16-bit values)
        {%r2, %r2, %r2, %r2, %r2, %r2, %r2, %r2}, // Matrix B (packed 16-bit values)
        {%f0, %f1, %f2, %f3, %f4, %f5, %f6, %f7}; // Accumulators (input)

    // Increment loop counter
    add.u32    %r0, %r0, 1;           // %r0 = %r0 + 1

    // Loop back
    bra        loop_start;

loop_exit:
    ret;                              // Return from kernel
}
